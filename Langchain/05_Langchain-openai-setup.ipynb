{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "756899f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "### Langsmith tracking\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ['LANGCHAIN_PROJECT']=os.getenv('LANGCHAIN_PROJECT')\n",
    "os.environ['LANGCHAIN_TRACING_V2']=\"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "085e68d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x0000026B192B7D90> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000026B1C0A98A0> root_client=<openai.OpenAI object at 0x0000026B192E7280> root_async_client=<openai.AsyncOpenAI object at 0x0000026B1BBF9F30> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model= 'gpt-4o')\n",
    "\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0634c859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Generative AI, often abbreviated as Gen AI, refers to a category of artificial intelligence systems designed to generate new content. This content can include text, images, music, and other media, based on the patterns and examples it has been trained on. Unlike traditional AI that might focus on recognizing patterns or making predictions, generative AI creates new data.\\n\\nExamples of generative AI models include:\\n\\n1. **Text Generation**: Models like OpenAI’s GPT-3 or GPT-4 can produce human-like text based on prompts given to them. They can assist in writing articles, creating dialogues, or even coding.\\n\\n2. **Image Generation**: Tools like DALL-E or Stable Diffusion generate images from textual descriptions, enabling users to create artwork, visuals, or concept designs from their imagination.\\n\\n3. **Music and Audio**: AI systems that compose music or generate sound effects based on user input or learned musical styles.\\n\\n4. **Video and Animation**: Although more complex, there are generative models that can produce videos, animations, or even deepfake content.\\n\\nGenerative AI leverages deep learning architectures, particularly variants of neural networks such as transformers, variational autoencoders (VAEs), and generative adversarial networks (GANs), to produce outputs that are increasingly indistinguishable from those made by humans. Its capabilities are both promising and challenging, as they open new possibilities in creative and professional fields but also raise ethical concerns like misinformation and copyright issues.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 297, 'prompt_tokens': 11, 'total_tokens': 308, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_90122d973c', 'id': 'chatcmpl-BXgg0xEXTgUcQs3SyXojWOgvqRNQ7', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--3ce254d7-b4c8-4d0c-8a3c-e3bb5d48c7c2-0' usage_metadata={'input_tokens': 11, 'output_tokens': 297, 'total_tokens': 308, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "### input and get response form LLM\n",
    "result= llm.invoke('what is gen ai')\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d3f5fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='you are an expert AI Enginee. Provide me answers based on questions'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\",\"you are an expert AI Enginee. Provide me answers based on questions\"),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4124e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"LangSmith, developed by LangChain, is a suite of tools designed to enhance the building, testing, and evaluation of AI applications. It focuses on helping developers improve the reliability and performance of large language models (LLMs) in real-world settings. LangSmith offers features for tracing, visualizing, and debugging LLM applications, thereby enabling developers to better understand the flow and execution of their projects. It also aids in testing the performance and accuracy of language models, facilitating experimentation with different prompts and configurations to optimize the application's output. Through these capabilities, LangSmith aims to streamline the development process and elevate the quality of AI-driven applications.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 127, 'prompt_tokens': 32, 'total_tokens': 159, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_55d88aaf2f', 'id': 'chatcmpl-BXgizSF9uAazZ15hiWyghjlVj6QQm', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--82cc3bb4-6a3c-40d7-b22f-c0488be586f8-0' usage_metadata={'input_tokens': 32, 'output_tokens': 127, 'total_tokens': 159, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "## chain\n",
    "chain = prompt | llm\n",
    "\n",
    "response= chain.invoke({\"input\":\"can you tell me about langsmith\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff091c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8060be5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Langsmith is a platform or tool often associated with facilitating the development and deployment of language models and natural language processing (NLP) applications. While specific details may vary depending on context or updates beyond my last training data in October 2023, platforms like Langsmith typically offer features such as model training, fine-tuning, and integration capabilities.\n",
      "\n",
      "Langsmith may provide an environment for developers to design, experiment, and implement sophisticated language models, often leveraging frameworks like TensorFlow or PyTorch. It might also include tools for dataset management, model performance evaluation, and possibly pre-trained models that users can adapt for specific tasks such as text generation, sentiment analysis, chatbots, or other AI-driven language-related applications.\n",
      "\n",
      "If this is a relatively new product or a specific service, further details should be available from official sources or the platform's documentation.\n"
     ]
    }
   ],
   "source": [
    "## stroutput Parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser=StrOutputParser()\n",
    "chain=prompt|llm|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db8bd31",
   "metadata": {},
   "source": [
    "### Simple Gen ai app with Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ce76233",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "## Data Ingestion--From the website we need to scrape the data\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader=WebBaseLoader(\"https://docs.smith.langchain.com/tutorials/Administrators/manage_spend\")\n",
    "\n",
    "\n",
    "docs=loader.load()\n",
    "\n",
    "### Load Data--> Docs-->Divide our Docuemnts into chunks dcouments-->text-->vectors-->Vector Embeddings--->Vector Store DB\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "documents=text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9dcdeef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://docs.smith.langchain.com/tutorials/Administrators/manage_spend', 'title': '🦜️🛠️ LangSmith', 'language': 'en'}, page_content='🦜️🛠️ LangSmith\\n\\n\\n\\n\\n\\n\\nSkip to main contentWe are growing and hiring for multiple roles for LangChain, LangGraph and LangSmith. Join our team!API ReferenceRESTPythonJS/TSSearchRegionUSEUGo to AppPage Not FoundWe could not find what you were looking for.Head back to our main docs page or use the search bar to find the page you need.CommunityTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2025 LangChain, Inc.')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6ccf019",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings=OpenAIEmbeddings()\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "vectorstoredb=FAISS.from_documents(documents,embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0d41208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x26b274ba1a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstoredb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d4849b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'🦜️🛠️ LangSmith\\n\\n\\n\\n\\n\\n\\nSkip to main contentWe are growing and hiring for multiple roles for LangChain, LangGraph and LangSmith. Join our team!API ReferenceRESTPythonJS/TSSearchRegionUSEUGo to AppPage Not FoundWe could not find what you were looking for.Head back to our main docs page or use the search bar to find the page you need.CommunityTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2025 LangChain, Inc.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Query From a vector db\n",
    "query=\"LangSmith has two usage limits: total traces and extended\"\n",
    "result=vectorstoredb.similarity_search(query)\n",
    "result[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7986ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f3f5691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\nAnswer the following question based only on the provided context:\\n<context>\\n{context}\\n</context>\\n\\n\\n'), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000026B26FE28F0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000026B274BBD30>, root_client=<openai.OpenAI object at 0x0000026B274BA410>, root_async_client=<openai.AsyncOpenAI object at 0x0000026B26FE3820>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Retrieval Chain, Document chain\n",
    "\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "Answer the following question based only on the provided context:\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "document_chain=create_stuff_documents_chain(llm,prompt)\n",
    "document_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc1cc6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangSmith has two usage limits: one for total traces and one for extended traces. These limits are represented by the two metrics tracked on their usage graph.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "document_chain.invoke({\n",
    "    \"input\":\"LangSmith has two usage limits: total traces and extended\",\n",
    "    \"context\":[Document(page_content=\"LangSmith has two usage limits: total traces and extended traces. These correspond to the two metrics we've been tracking on our usage graph. \")]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d16e1d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x26b274ba1a0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Input--->Retriever--->vectorstoredb\n",
    "\n",
    "vectorstoredb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9119032d",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=vectorstoredb.as_retriever()\n",
    "from langchain.chains import create_retrieval_chain\n",
    "retrieval_chain=create_retrieval_chain(retriever,document_chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08f4909a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000026B274BA1A0>, search_kwargs={}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\nAnswer the following question based only on the provided context:\\n<context>\\n{context}\\n</context>\\n\\n\\n'), additional_kwargs={})])\n",
       "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000026B26FE28F0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000026B274BBD30>, root_client=<openai.OpenAI object at 0x0000026B274BA410>, root_async_client=<openai.AsyncOpenAI object at 0x0000026B26FE3820>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "beb2a1f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The context does not provide specific information about LangSmith, such as what it is or its features. However, it mentions that LangSmith is associated with LangChain, LangGraph, and various roles and tools like SDKs for Python and JS/TS. If you have any particular questions about LangSmith based on this context, feel free to ask!'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get the response form the LLM\n",
    "response=retrieval_chain.invoke({\"input\":\"LangSmith has two usage limits: total traces and extended\"})\n",
    "response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd6c8dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'LangSmith has two usage limits: total traces and extended',\n",
       " 'context': [Document(id='017c88bd-75e3-4993-a6db-68106faa4519', metadata={'source': 'https://docs.smith.langchain.com/tutorials/Administrators/manage_spend', 'title': '🦜️🛠️ LangSmith', 'language': 'en'}, page_content='🦜️🛠️ LangSmith\\n\\n\\n\\n\\n\\n\\nSkip to main contentWe are growing and hiring for multiple roles for LangChain, LangGraph and LangSmith. Join our team!API ReferenceRESTPythonJS/TSSearchRegionUSEUGo to AppPage Not FoundWe could not find what you were looking for.Head back to our main docs page or use the search bar to find the page you need.CommunityTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2025 LangChain, Inc.')],\n",
       " 'answer': 'The context does not provide specific information about LangSmith, such as what it is or its features. However, it mentions that LangSmith is associated with LangChain, LangGraph, and various roles and tools like SDKs for Python and JS/TS. If you have any particular questions about LangSmith based on this context, feel free to ask!'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba04f33c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='017c88bd-75e3-4993-a6db-68106faa4519', metadata={'source': 'https://docs.smith.langchain.com/tutorials/Administrators/manage_spend', 'title': '🦜️🛠️ LangSmith', 'language': 'en'}, page_content='🦜️🛠️ LangSmith\\n\\n\\n\\n\\n\\n\\nSkip to main contentWe are growing and hiring for multiple roles for LangChain, LangGraph and LangSmith. Join our team!API ReferenceRESTPythonJS/TSSearchRegionUSEUGo to AppPage Not FoundWe could not find what you were looking for.Head back to our main docs page or use the search bar to find the page you need.CommunityTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2025 LangChain, Inc.')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29849a87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
