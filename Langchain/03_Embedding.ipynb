{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a5a2893",
   "metadata": {},
   "source": [
    "#### **What are Embeddings?**\n",
    "Embeddings are high-dimensional vector representations of text. They allow you to encode the meaning of text in a way that a machine can compare and retrieve semantically similar content.\n",
    "\n",
    "In a RAG pipeline, embeddings help match user queries with the most relevant document chunks based on semantic similarity, not just keyword matching.\n",
    "\n",
    "#### **Embedding Step in LangChain (Deep Dive)**\n",
    "In LangChain, the embedding step follows text loading and text splitting, and comes before storing or retrieving from a vector database.\n",
    "\n",
    "#### **Key Concepts**\n",
    "1. Text Input: Usually a list of strings (chunks of documents).\n",
    "2. Embedding Model: Transforms text into vectors.\n",
    "3. Output: A list of vectors (float arrays).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058cef6d",
   "metadata": {},
   "source": [
    "**Embedding Models in LangChain**: LangChain abstracts embedding models behind a standard interface using Embeddings class:\n",
    "\n",
    "| Provider                               | LangChain Class         | Notes                              |\n",
    "| -------------------------------------- | ----------------------- | ---------------------------------- |\n",
    "| **OpenAI**                             | `OpenAIEmbeddings`      | Uses `text-embedding-ada-002`      |\n",
    "| **Hugging Face**                       | `HuggingFaceEmbeddings` | Local or hosted transformers       |\n",
    "| **Cohere**                             | `CohereEmbeddings`      | Fast and scalable                  |\n",
    "| **Google Vertex AI**                   | `VertexAIEmbeddings`    | Google’s models                    |\n",
    "| **Azure OpenAI**                       | `AzureOpenAIEmbeddings` | Same as OpenAI but hosted on Azure |\n",
    "| **Local** (e.g. Sentence Transformers) | `HuggingFaceEmbeddings` | No API call, great for privacy     |\n",
    "\n",
    "\n",
    "**Choosing Right Embedding Model**:\n",
    "| Use Case                  | Suggested Embedding Model     |\n",
    "| ------------------------- | ----------------------------- |\n",
    "| General-purpose (cloud)   | `OpenAIEmbeddings`            |\n",
    "| Open-source/local         | `HuggingFaceEmbeddings`       |\n",
    "| Privacy-sensitive         | Sentence Transformers (local) |\n",
    "| High-scale commercial use | `CohereEmbeddings`            |\n",
    "\n",
    "\n",
    "**Tips for Better Embedding Usage**:\n",
    "1. Clean and chunk text well before embedding.\n",
    "2. Avoid embedding too-long texts; keep chunks ≤ 1000 tokens.\n",
    "3. Ensure the same embedding model is used for both indexing and querying.\n",
    "4. Consider using embedding caching for speed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73ec9125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "064b2157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x000001ED502C1C60>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x000001ED5075CD60>, model='text-embedding-3-large', dimensions=None, deployment='text-embedding-ada-002', openai_api_version=None, openai_api_base=None, openai_api_type=None, openai_proxy=None, embedding_ctx_length=8191, openai_api_key=SecretStr('**********'), openai_organization=None, allowed_special=None, disallowed_special=None, chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None, http_async_client=None, check_embedding_ctx_length=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model= 'text-embedding-3-large')\n",
    "\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd3f4d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\disha\\AppData\\Local\\Temp\\ipykernel_10856\\4128701652.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
      "c:\\Users\\disha\\miniconda3\\envs\\rag-env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.043438367545604706, -0.02323009818792343, -0.019097167998552322, 0.02411555126309395, -0.0035267199855297804]\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "model_name = 'sentence-transformers/all-MiniLM-L6-v2'  # Free and light\n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "\n",
    "embeddingstext = 'i am physics undergraduate student'\n",
    "query_result = embeddings.embed_query(embeddingstext)\n",
    "\n",
    "print(query_result[:5])  # Print first 5 dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2e99e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd06e8e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'quantum.txt'}, page_content='Quantum Mechanics: An Overview\\nQuantum mechanics is a fundamental branch of physics that describes nature at the smallest scales of energy levels of atoms and subatomic particles. Unlike classical mechanics, where objects have definite positions and velocities, quantum mechanics introduces a probabilistic framework. Particles are described by wave functions, and these wave functions provide the probabilities of finding a particle in a particular location or state.\\n\\nWave-Particle Duality\\nOne of the most profound revelations of quantum mechanics is that particles, such as electrons and photons, exhibit both wave-like and particle-like properties. This dual nature was highlighted in the famous double-slit experiment, where particles produce an interference pattern typical of waves when not observed, but behave like discrete particles when measured.\\n\\nThe Uncertainty Principle\\nProposed by Werner Heisenberg, the uncertainty principle states that one cannot simultaneously know both the exact position and momentum of a particle. Mathematically, the product of the uncertainties in position and momentum is always greater than or equal to a constant (ℏ/2). This principle reflects a fundamental limit to what can be known and is not due to measurement flaws.\\n\\nQuantum Superposition\\nSuperposition is a core concept that allows quantum systems to exist in multiple states at once. For example, an electron in an atom can be in a superposition of several energy states until it is measured. The act of measurement collapses the wave function, forcing the system into one of the possible states.\\n\\nEntanglement\\nQuantum entanglement is a phenomenon where two or more particles become linked and instantaneously affect each other\\'s states, no matter how far apart they are. Einstein referred to this as \"spooky action at a distance.\" Entanglement has been experimentally verified and is a key resource in quantum computing and quantum cryptography.\\n\\nThe Schrödinger Equation\\nThe behavior of quantum systems is governed by the Schrödinger equation, a differential equation that describes how the quantum state of a physical system changes over time. The equation\\'s solutions are wave functions, which encode all possible information about the system\\'s state.\\n\\nMeasurement Problem and Interpretations\\nThe measurement problem arises from the transition of a quantum system from a superposition to a definite state upon observation. Different interpretations have been proposed, including the Copenhagen interpretation (which emphasizes wave function collapse), the many-worlds interpretation (which posits all outcomes occur in parallel universes), and pilot-wave theories.\\n\\nQuantum Tunneling\\nQuantum tunneling is the phenomenon where particles pass through energy barriers higher than their kinetic energy. This effect is critical in nuclear fusion in stars and the operation of tunnel diodes and scanning tunneling microscopes.\\n\\nApplications of Quantum Mechanics\\nQuantum mechanics has led to revolutionary technologies, including semiconductors, lasers, magnetic resonance imaging (MRI), and quantum computers. Quantum cryptography, using principles like entanglement and superposition, offers the promise of unbreakable encryption.\\n\\nQuantum Computing\\nQuantum computing harnesses the power of qubits, which can exist in superpositions of states. Quantum algorithms such as Shor\\'s (for factoring large numbers) and Grover\\'s (for search problems) demonstrate potential exponential speedups over classical counterparts. While still in its early stages, quantum computing could revolutionize fields from cryptography to drug discovery.\\n\\n\\n')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader('quantum.txt')\n",
    "docs = loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f6e85ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'quantum.txt'}, page_content='Quantum Mechanics: An Overview\\nQuantum mechanics is a fundamental branch of physics that describes nature at the smallest scales of energy levels of atoms and subatomic particles. Unlike classical mechanics, where objects have definite positions and velocities, quantum mechanics introduces a probabilistic framework. Particles are described by wave functions, and these wave functions provide the probabilities of finding a particle in a particular location or state.'),\n",
       " Document(metadata={'source': 'quantum.txt'}, page_content='Wave-Particle Duality\\nOne of the most profound revelations of quantum mechanics is that particles, such as electrons and photons, exhibit both wave-like and particle-like properties. This dual nature was highlighted in the famous double-slit experiment, where particles produce an interference pattern typical of waves when not observed, but behave like discrete particles when measured.'),\n",
       " Document(metadata={'source': 'quantum.txt'}, page_content='The Uncertainty Principle\\nProposed by Werner Heisenberg, the uncertainty principle states that one cannot simultaneously know both the exact position and momentum of a particle. Mathematically, the product of the uncertainties in position and momentum is always greater than or equal to a constant (ℏ/2). This principle reflects a fundamental limit to what can be known and is not due to measurement flaws.'),\n",
       " Document(metadata={'source': 'quantum.txt'}, page_content='Quantum Superposition\\nSuperposition is a core concept that allows quantum systems to exist in multiple states at once. For example, an electron in an atom can be in a superposition of several energy states until it is measured. The act of measurement collapses the wave function, forcing the system into one of the possible states.'),\n",
       " Document(metadata={'source': 'quantum.txt'}, page_content='Entanglement\\nQuantum entanglement is a phenomenon where two or more particles become linked and instantaneously affect each other\\'s states, no matter how far apart they are. Einstein referred to this as \"spooky action at a distance.\" Entanglement has been experimentally verified and is a key resource in quantum computing and quantum cryptography.'),\n",
       " Document(metadata={'source': 'quantum.txt'}, page_content=\"The Schrödinger Equation\\nThe behavior of quantum systems is governed by the Schrödinger equation, a differential equation that describes how the quantum state of a physical system changes over time. The equation's solutions are wave functions, which encode all possible information about the system's state.\"),\n",
       " Document(metadata={'source': 'quantum.txt'}, page_content='Measurement Problem and Interpretations\\nThe measurement problem arises from the transition of a quantum system from a superposition to a definite state upon observation. Different interpretations have been proposed, including the Copenhagen interpretation (which emphasizes wave function collapse), the many-worlds interpretation (which posits all outcomes occur in parallel universes), and pilot-wave theories.'),\n",
       " Document(metadata={'source': 'quantum.txt'}, page_content='Quantum Tunneling\\nQuantum tunneling is the phenomenon where particles pass through energy barriers higher than their kinetic energy. This effect is critical in nuclear fusion in stars and the operation of tunnel diodes and scanning tunneling microscopes.'),\n",
       " Document(metadata={'source': 'quantum.txt'}, page_content='Applications of Quantum Mechanics\\nQuantum mechanics has led to revolutionary technologies, including semiconductors, lasers, magnetic resonance imaging (MRI), and quantum computers. Quantum cryptography, using principles like entanglement and superposition, offers the promise of unbreakable encryption.'),\n",
       " Document(metadata={'source': 'quantum.txt'}, page_content=\"Quantum Computing\\nQuantum computing harnesses the power of qubits, which can exist in superpositions of states. Quantum algorithms such as Shor's (for factoring large numbers) and Grover's (for search problems) demonstrate potential exponential speedups over classical counterparts. While still in its early stages, quantum computing could revolutionize fields from cryptography to drug discovery.\")]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=50)\n",
    "final_documents=text_splitter.split_documents(docs)\n",
    "final_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eff0f6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.chroma.Chroma at 0x1ed4d9f8af0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Vector Embedding And Vector StoreDB\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "db=Chroma.from_documents(final_documents,embeddings)\n",
    "db\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b65676d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'quantum.txt'}, page_content=\"Quantum Computing\\nQuantum computing harnesses the power of qubits, which can exist in superpositions of states. Quantum algorithms such as Shor's (for factoring large numbers) and Grover's (for search problems) demonstrate potential exponential speedups over classical counterparts. While still in its early stages, quantum computing could revolutionize fields from cryptography to drug discovery.\"), Document(metadata={'source': 'quantum.txt'}, page_content='Applications of Quantum Mechanics\\nQuantum mechanics has led to revolutionary technologies, including semiconductors, lasers, magnetic resonance imaging (MRI), and quantum computers. Quantum cryptography, using principles like entanglement and superposition, offers the promise of unbreakable encryption.'), Document(metadata={'source': 'quantum.txt'}, page_content='Measurement Problem and Interpretations\\nThe measurement problem arises from the transition of a quantum system from a superposition to a definite state upon observation. Different interpretations have been proposed, including the Copenhagen interpretation (which emphasizes wave function collapse), the many-worlds interpretation (which posits all outcomes occur in parallel universes), and pilot-wave theories.'), Document(metadata={'source': 'quantum.txt'}, page_content='Entanglement\\nQuantum entanglement is a phenomenon where two or more particles become linked and instantaneously affect each other\\'s states, no matter how far apart they are. Einstein referred to this as \"spooky action at a distance.\" Entanglement has been experimentally verified and is a key resource in quantum computing and quantum cryptography.')]\n"
     ]
    }
   ],
   "source": [
    "### Retrieve the results from query vectorstore db\n",
    "query=\"It will be all the easier for us to conduct ourselves as belligerents\"\n",
    "retrieved_results=db.similarity_search(query)\n",
    "print(retrieved_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6adf55f",
   "metadata": {},
   "source": [
    "### **OLAMA**\n",
    "Ollama supports embedding models, making it possible to build retrieval augmented generation (RAG) applications that combine text prompts with existing documents or other data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68d3b00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "embeddings =(\n",
    "    OllamaEmbeddings(model= 'nomic-embed-text')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "842ef2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OllamaEmbeddings(base_url='http://localhost:11434', model='nomic-embed-text', embed_instruction='passage: ', query_instruction='query: ', mirostat=None, mirostat_eta=None, mirostat_tau=None, num_ctx=None, num_gpu=None, num_thread=None, repeat_last_n=None, repeat_penalty=None, temperature=None, stop=None, tfs_z=None, top_k=None, top_p=None, show_progress=False, headers=None, model_kwargs=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1b68cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1=embeddings.embed_documents(\n",
    "    [\n",
    "       \"Alpha is the first letter of Greek alphabet\",\n",
    "       \"Beta is the second letter of Greek alphabet\", \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db280a7",
   "metadata": {},
   "source": [
    "### Hugging face embeddings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
